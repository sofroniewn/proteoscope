image_embedding_dims: 2500
protein_embedding_dims: 2560
projection_dims: 1024
dropout: 0.2
classifier_weight: 1.0
esm:
  d_model: 2560 # cross_attention_dim 1280 2560
  model_name: 'esm2_t36_3B_UR50D' # esm2_t33_650M_UR50D
  embedding_layer: 36 # 33 36
  truncation_seq_length: 1024
  lora:
    target_modules:
      - "k_proj"
      - "v_proj"
      - "q_proj"
      - "out_proj"
    inference_mode: False
    r: 4
    lora_alpha: 4
    lora_dropout: 0.1
esm_bottleneck:
  d_init: 2560
  d_model: 0 # cross_attention_dim
  nhead: 4
  num_encoder_layers: 0
  dim_feedforward: 256
  dropout: 0.2
  return_type: 'full'
cytoself:
  checkpoint: /home/ec2-user/outputs/cytoself/2023-09-02/05-17-26/checkpoints/last.ckpt # 2023-08-21/19-45-50 2023-08-17/05-03-37
  num_class: 1311 # 1311 or 1049
  model:
    input_shape: [2, 100, 100]
    emb_shapes: [[25, 25], [4, 4]]
    output_shape: [2, 100, 100]
    fc_output_idx: [2]
    vq_args:
      num_embeddings: 2048
      embedding_dim: 64
    fc_args:
      num_layers: 2
    fc_input_type: 'vqvec'
    num_class: null
    vq_coeff: 1.0
    fc_coeff: 1.0
    image_variance: 0.0167