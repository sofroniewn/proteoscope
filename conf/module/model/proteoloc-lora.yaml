d_model: 1280 # cross_attention_dim 1280 2560
num_class: 10
esm_model: 'esm2_t33_650M_UR50D' # esm2_t33_650M_UR50D
embedding_layer: 33 # 33 36
truncation_seq_length: 1024
lora:
  target_modules:
    - "k_proj"
    - "v_proj"
    - "q_proj"
    - "out_proj"
  inference_mode: False
  r: 4
  lora_alpha: 4
  lora_dropout: 0.1