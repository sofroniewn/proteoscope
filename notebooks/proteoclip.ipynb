{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14781/3095700002.py:18: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  with hydra.initialize_config_dir(config_dir=config_dir):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Using  /home/ec2-user/outputs/proteoclip/2023-09-20/01-06-01/checkpoints/last.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/proteoscope/proteoscope/data/datamodule.py:43: DtypeWarning: Columns (17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  self.labels = pd.read_csv(self.labels_path, index_col=0)\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/envs/pytorch/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n"
     ]
    }
   ],
   "source": [
    "import hydra\n",
    "from glob import  glob\n",
    "from proteoscope.data import ProteoscopeDM\n",
    "from proteoscope.modules import ProteoclipLM\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "\n",
    "BASE_DIR = \"/home/ec2-user/outputs/proteoclip/2023-09-20/01-06-01\" # Best proteoscope - ESM-full\n",
    "# BASE_DIR = \"/home/ec2-user/outputs/proteoclip/2023-09-20/00-54-19\" # Best proteoscope - ESM-full\n",
    "\n",
    "# BASE_DIR = \"/home/ec2-user/outputs-proteoscope/2023-08-04/16-34-38\" # 25 x 25 cond latent\n",
    "# BASE_DIR = \"/home/ec2-user/outputs-proteoscope/2023-08-04/22-36-50\" # 25 x 25 cond nuclei + latent\n",
    "# BASE_DIR = \"/home/ec2-user/outputs-proteoscope/2023-08-05/01-50-26\" # 25 x 25 cond nuclei + latent\n",
    "\n",
    "config_dir = BASE_DIR + \"/.hydra\"\n",
    "\n",
    "with hydra.initialize_config_dir(config_dir=config_dir):\n",
    "    config = hydra.compose(config_name=\"config\", overrides=OmegaConf.load(config_dir + \"/overrides.yaml\"))\n",
    "\n",
    "    chkpts = glob(BASE_DIR + \"/checkpoints/*.ckpt\")\n",
    "    chkpts.sort()\n",
    "    chkpt = chkpts[-1]\n",
    "    print('   Using ', chkpt)\n",
    "\n",
    "\n",
    "    pdm = ProteoscopeDM(\n",
    "        images_path=config.data.images_path,\n",
    "        labels_path=config.data.labels_path,\n",
    "        trim=config.data.trim,\n",
    "        sequences_path=config.data.sequences_path,\n",
    "        batch_size=config.trainer.batch_size,\n",
    "        num_workers=config.trainer.num_workers,\n",
    "        sequence_embedding=config.data.sequence_embedding,\n",
    "        splits=config.splits,\n",
    "        sequence_dropout=config.data.sequence_dropout\n",
    "    )\n",
    "    pdm.setup()\n",
    "\n",
    "    plm = ProteoclipLM.load_from_checkpoint(\n",
    "        chkpt,\n",
    "        module_config=config.module,\n",
    "    )\n",
    "\n",
    "    plm.eval()\n",
    "    plm.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = pdm.test_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ec2-user/proteoscope/notebooks/proteoclip.ipynb Cell 4\u001b[0m in \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2-3/home/ec2-user/proteoscope/notebooks/proteoclip.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m true_labels \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2-3/home/ec2-user/proteoscope/notebooks/proteoclip.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m predicted_labels \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2-3/home/ec2-user/proteoscope/notebooks/proteoclip.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(dl):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2-3/home/ec2-user/proteoscope/notebooks/proteoclip.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     batch[\u001b[39m'\u001b[39m\u001b[39msequence_embed\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39msequence_embed\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2-3/home/ec2-user/proteoscope/notebooks/proteoclip.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     batch[\u001b[39m'\u001b[39m\u001b[39msequence_mask\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m batch[\u001b[39m'\u001b[39m\u001b[39msequence_mask\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)    \n",
      "\u001b[0;31mNameError\u001b[0m: name 'dl' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import  tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "for batch in tqdm(dl):\n",
    "    batch['sequence_embed'] = batch['sequence_embed'].to('cuda')\n",
    "    batch['sequence_mask'] = batch['sequence_mask'].to('cuda')    \n",
    "    batch['truncation'] = batch['truncation'].to('cuda')    \n",
    "    logits = plm(batch)\n",
    "    prediction = torch.argmax(logits, -1)\n",
    "    predicted_labels.append(prediction.detach().cpu().numpy())\n",
    "    true_labels.append(batch['localization'].detach().cpu().numpy())\n",
    "true_labels = np.concatenate(true_labels, axis=0)\n",
    "predicted_labels = np.concatenate(predicted_labels, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "\n",
    "acc = accuracy_score(true_labels, predicted_labels)\n",
    "print(f'Accuracy {acc}')\n",
    "\n",
    "cm = confusion_matrix(true_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(cm / cm.sum(axis=1)[:, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on OpenCell protein embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# seq_path = '/home/ec2-user/cytoself-data/sequences.csv'\n",
    "# seq = pd.read_csv(seq_path, index_col=0)\n",
    "# # seq['Length'] = seq[\"Peptide\"].apply(lambda x: len(x.replace(\"*\", \"\")))\n",
    "# # seq.to_csv(seq_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proteoscope.data import ProteolocDM\n",
    "\n",
    "\n",
    "plds = ProteolocDM(\n",
    "    labels_path='/home/ec2-user/cytoself-data/sequences.csv',\n",
    "    sequences_path=None, #'/home/ec2-user/cytoself-data/esm2_t36_3B_UR50D.zarr', #None, '/home/ec2-user/cytoself-data/ESM_sequence_embeddings_full.zarr',\n",
    "    batch_size=1,\n",
    "    num_workers=0,\n",
    "    sequence_embedding=None, #'ESM-full', # None, 'ESM-full',\n",
    ")\n",
    "plds.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plm.protein_projection = plm.protein_projection.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1311/1311 [01:47<00:00, 12.24it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import  tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "embeds = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(plds.predict_dataloader()):\n",
    "        # batch['sequence_embed'] = batch['sequence_embed'].to('cuda')\n",
    "        # batch['sequence_mask'] = batch['sequence_mask'].to('cuda')    \n",
    "        batch['truncation'] = batch['truncation'].to('cuda')    \n",
    "        seq_embeds = plm.embed(batch)\n",
    "        embeds.append(seq_embeds.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeds = np.concatenate(embeds, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For protein embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import os\n",
    "\n",
    "PROTEIN_EMBED_PATH = '/home/ec2-user/cytoself-data/ESM_sequence_embeddings_clip_lora.zarr'\n",
    "\n",
    "z_embedding_prot = zarr.open(\n",
    "    PROTEIN_EMBED_PATH,\n",
    "    mode=\"w\",\n",
    "        shape=(len(embeds), config.module.model.projection_dims),\n",
    "        chunks=(1, None),\n",
    "    dtype=\"float32\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_embedding_prot[:, :] = embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1311, 1024)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_embedding_prot.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For Sequence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import os\n",
    "\n",
    "\n",
    "# PROTEIN_EMBED_PATH = '/home/ec2-user/cytoself-data/ESM_sequence_embeddings_full_lora3.zarr'\n",
    "\n",
    "\n",
    "z_embedding_prot = zarr.open(\n",
    "    PROTEIN_EMBED_PATH,\n",
    "    mode=\"w\",\n",
    "        shape=(len(embeds), config.module.model.truncation_seq_length + 1, config.module.model.d_model),\n",
    "        chunks=(1, None, None),\n",
    "    dtype=\"float32\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, zz in enumerate(embeds):\n",
    "    ll = min(1024, len(zz[0]))\n",
    "    z_embedding_prot[i, 1:1+ll, :] = zz[0][:ll]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esm.esmfold.v1.esmfold import ESMFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, TaskType\n",
    "import esm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pytorch_lightning\n",
    "\n",
    "# Create a module for the old path\n",
    "sys.modules['pytorch_lightning.utilities.seed'] = sys.modules['lightning_fabric.utilities.seed']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = esm.pretrained.esmfold_v1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = \"MKTVRQERLKSIVRILERSKEPVSGAQLAEELSVSRQVIVQDIAYLRSLGYNIVATPRGYVLAGG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = esm.data.Alphabet.from_architecture(\"ESM-1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = alphabet.get_batch_converter(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda().half();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "a = ['a'] * n\n",
    "b = ['M' * 1024] * n\n",
    "\n",
    "result = list(zip(a, b))\n",
    "labels, strs, toks = converter(result)\n",
    "toks = toks.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model.esm(\n",
    "    toks,\n",
    "    repr_layers=range(model.esm.num_layers + 1),\n",
    ")\n",
    "esm_s = torch.stack(\n",
    "    [v for _, v in sorted(res[\"representations\"].items())], dim=2\n",
    ")\n",
    "# Drop BOS/EOS\n",
    "esm_s = esm_s[:, 1:-1]  # B, L, nLayers,\n",
    "esm_s = esm_s.to(model.esm_s_combine.dtype)\n",
    "esm_s = esm_s.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "esm_sm = (model.esm_s_combine.softmax(0).unsqueeze(0) @ esm_s).squeeze(2)\n",
    "\n",
    "s_s_0 = model.esm_s_mlp(esm_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1024, 1024])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_s_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_params = [p for p in model.parameters() if p.requires_grad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(trainable_params) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 162.00 MiB (GPU 0; 15.78 GiB total capacity; 14.53 GiB already allocated; 22.19 MiB free; 14.86 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m/home/ec2-user/proteoscope/notebooks/proteoloc.ipynb Cell 22\u001b[0m in \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2-3/home/ec2-user/proteoscope/notebooks/proteoloc.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2-3/home/ec2-user/proteoscope/notebooks/proteoloc.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m out \u001b[39m=\u001b[39m model(toks, repr_layers\u001b[39m=\u001b[39;49m[\u001b[39m33\u001b[39;49m], return_contacts\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2-3/home/ec2-user/proteoscope/notebooks/proteoloc.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m output \u001b[39m=\u001b[39m out[\u001b[39m'\u001b[39m\u001b[39mrepresentations\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m33\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Baws-ec2-3/home/ec2-user/proteoscope/notebooks/proteoloc.ipynb#X46sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m loss \u001b[39m=\u001b[39m criterion(output, torch\u001b[39m.\u001b[39mzeros_like(output))\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/peft/peft_model.py:442\u001b[0m, in \u001b[0;36mPeftModel.forward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any):\n\u001b[1;32m    439\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    440\u001b[0m \u001b[39m    Forward pass of the model.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 442\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_base_model()(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/esm/model/esm2.py:112\u001b[0m, in \u001b[0;36mESM2.forward\u001b[0;34m(self, tokens, repr_layers, need_head_weights, return_contacts)\u001b[0m\n\u001b[1;32m    109\u001b[0m     padding_mask \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    111\u001b[0m \u001b[39mfor\u001b[39;00m layer_idx, layer \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers):\n\u001b[0;32m--> 112\u001b[0m     x, attn \u001b[39m=\u001b[39m layer(\n\u001b[1;32m    113\u001b[0m         x,\n\u001b[1;32m    114\u001b[0m         self_attn_padding_mask\u001b[39m=\u001b[39;49mpadding_mask,\n\u001b[1;32m    115\u001b[0m         need_head_weights\u001b[39m=\u001b[39;49mneed_head_weights,\n\u001b[1;32m    116\u001b[0m     )\n\u001b[1;32m    117\u001b[0m     \u001b[39mif\u001b[39;00m (layer_idx \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39min\u001b[39;00m repr_layers:\n\u001b[1;32m    118\u001b[0m         hidden_representations[layer_idx \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/esm/modules.py:125\u001b[0m, in \u001b[0;36mTransformerLayer.forward\u001b[0;34m(self, x, self_attn_mask, self_attn_padding_mask, need_head_weights)\u001b[0m\n\u001b[1;32m    123\u001b[0m residual \u001b[39m=\u001b[39m x\n\u001b[1;32m    124\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_attn_layer_norm(x)\n\u001b[0;32m--> 125\u001b[0m x, attn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(\n\u001b[1;32m    126\u001b[0m     query\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m    127\u001b[0m     key\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m    128\u001b[0m     value\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m    129\u001b[0m     key_padding_mask\u001b[39m=\u001b[39;49mself_attn_padding_mask,\n\u001b[1;32m    130\u001b[0m     need_weights\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    131\u001b[0m     need_head_weights\u001b[39m=\u001b[39;49mneed_head_weights,\n\u001b[1;32m    132\u001b[0m     attn_mask\u001b[39m=\u001b[39;49mself_attn_mask,\n\u001b[1;32m    133\u001b[0m )\n\u001b[1;32m    134\u001b[0m x \u001b[39m=\u001b[39m residual \u001b[39m+\u001b[39m x\n\u001b[1;32m    136\u001b[0m residual \u001b[39m=\u001b[39m x\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:1190\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1187\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1191\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/envs/pytorch/lib/python3.9/site-packages/esm/multihead_attention.py:380\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[0;34m(self, query, key, value, key_padding_mask, incremental_state, need_weights, static_kv, attn_mask, before_softmax, need_head_weights)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_weights, v\n\u001b[1;32m    379\u001b[0m attn_weights_float \u001b[39m=\u001b[39m utils_softmax(attn_weights, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, onnx_trace\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39monnx_trace)\n\u001b[0;32m--> 380\u001b[0m attn_weights \u001b[39m=\u001b[39m attn_weights_float\u001b[39m.\u001b[39;49mtype_as(attn_weights)\n\u001b[1;32m    381\u001b[0m attn_probs \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mdropout(\n\u001b[1;32m    382\u001b[0m     attn_weights_float\u001b[39m.\u001b[39mtype_as(attn_weights),\n\u001b[1;32m    383\u001b[0m     p\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout,\n\u001b[1;32m    384\u001b[0m     training\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining,\n\u001b[1;32m    385\u001b[0m )\n\u001b[1;32m    386\u001b[0m \u001b[39massert\u001b[39;00m v \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 162.00 MiB (GPU 0; 15.78 GiB total capacity; 14.53 GiB already allocated; 22.19 MiB free; 14.86 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "optimizer.zero_grad()\n",
    "out = model(toks, repr_layers=[33], return_contacts=False)\n",
    "output = out['representations'][33]\n",
    "loss = criterion(output, torch.zeros_like(output))\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer.zero_grad()  # Assuming you have defined an optimizer\n",
    "# output = model(dummy_input)\n",
    "# loss = criterion(output, dummy_target)\n",
    "# loss.backward()\n",
    "# optimizer.step()  # Opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.parameters())[0].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable = 0\n",
    "not_trainable = 0\n",
    "for p in model.parameters():\n",
    "    if p.requires_grad:\n",
    "        trainable += p.numel()\n",
    "    else:\n",
    "        not_trainable += p.numel()\n",
    "print(trainable, not_trainable, trainable / (trainable + not_trainable) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(target_modules=[\"k_proj\", \"v_proj\", \"q_proj\", \"out_proj\"], inference_mode=False, r=4, lora_alpha=4, lora_dropout=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,351,680 || all params: 652,394,934 || trainable%: 0.20718738444403678\n"
     ]
    }
   ],
   "source": [
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable = 0\n",
    "not_trainable = 0\n",
    "for p in model.parameters():\n",
    "    if p.requires_grad:\n",
    "        trainable += p.numel()\n",
    "    else:\n",
    "        not_trainable += p.numel()\n",
    "print(trainable, not_trainable, trainable / (trainable + not_trainable) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_path = '/home/ec2-user/cytoself-data/labels.csv'\n",
    "data_path2 = '/home/ec2-user/cytoself-data/sequences.csv'\n",
    "df = pd.read_csv(data_path, index_col=0)\n",
    "df2 = pd.read_csv(data_path2, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['loc'] = df2['localization'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(data_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
