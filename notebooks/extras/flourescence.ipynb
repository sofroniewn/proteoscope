{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchdrug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torchdrug.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchdrug import datasets\n",
    "\n",
    "BASE_PATH = \"/home/ec2-user/esm/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03:13:29   Downloading http://s3.amazonaws.com/songlabdata/proteindata/data_pytorch/fluorescence.tar.gz to /home/ec2-user/esm/fluorescence.tar.gz\n",
      "03:13:30   Extracting /home/ec2-user/esm/fluorescence.tar.gz to /home/ec2-user/esm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Constructing proteins from sequences: 100%|██████████| 54025/54025 [01:12<00:00, 747.43it/s]\n"
     ]
    }
   ],
   "source": [
    "from torchdrug import transforms\n",
    "from torchdrug import datasets\n",
    "\n",
    "truncate_transform = transforms.TruncateProtein(max_length=1024, random=False)\n",
    "protein_view_transform = transforms.ProteinView(view=\"residue\")\n",
    "transform = transforms.Compose([truncate_transform, protein_view_transform])\n",
    "# dataset = datasets.SubcellularLocalization(SUBCELLULAR_PATH, atom_feature=None, bond_feature=None, residue_feature=\"default\", transform=transform)\n",
    "dataset = datasets.Fluorescence(BASE_PATH, atom_feature=None, bond_feature=None, residue_feature=\"default\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'graph': Protein(num_atom=0, num_bond=0, num_residue=237),\n",
       " 'log_fluorescence': 3.8237006664276123}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, valid_set, test_set = dataset.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The label of first sample:  3.8237006664276123\n",
      "train samples: 21446, valid samples: 5362, test samples: 27217\n"
     ]
    }
   ],
   "source": [
    "print(\"The label of first sample: \", dataset[0][dataset.target_fields[0]])\n",
    "print(\"train samples: %d, valid samples: %d, test samples: %d\" % (len(train_set), len(valid_set), len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prot_seq = dataset[0]['graph'].to_sequence().replace('.', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21446/21446 [00:11<00:00, 1885.85it/s]\n",
      "100%|██████████| 5362/5362 [00:02<00:00, 1949.96it/s]\n",
      "100%|██████████| 27217/27217 [00:14<00:00, 1939.00it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "seq = []\n",
    "for item in tqdm(train_set):\n",
    "    aa = item['graph'].to_sequence().replace('.', '')\n",
    "    lf = item['log_fluorescence']\n",
    "    seq.append({'seq': aa, 'loc': lf, 'split': 'train'})\n",
    "\n",
    "for item in tqdm(valid_set):\n",
    "    aa = item['graph'].to_sequence().replace('.', '')\n",
    "    lf = item['log_fluorescence']\n",
    "    seq.append({'seq': aa, 'loc': lf, 'split': 'val'})\n",
    "\n",
    "for item in tqdm(test_set):\n",
    "    aa = item['graph'].to_sequence().replace('.', '')\n",
    "    lf = item['log_fluorescence']\n",
    "    seq.append({'seq': aa, 'loc': lf, 'split': 'test'})\n",
    "\n",
    "seq = pd.DataFrame(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq.to_csv('protein_lf.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train flourescence model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "seq = pd.read_csv('protein_lf.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>loc</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...</td>\n",
       "      <td>3.823701</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...</td>\n",
       "      <td>3.752084</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...</td>\n",
       "      <td>3.540156</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...</td>\n",
       "      <td>3.691572</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...</td>\n",
       "      <td>3.688143</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54020</th>\n",
       "      <td>SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...</td>\n",
       "      <td>1.565922</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54021</th>\n",
       "      <td>SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...</td>\n",
       "      <td>1.532945</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54022</th>\n",
       "      <td>SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...</td>\n",
       "      <td>1.529521</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54023</th>\n",
       "      <td>SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...</td>\n",
       "      <td>1.301030</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54024</th>\n",
       "      <td>SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...</td>\n",
       "      <td>1.302130</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54025 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     seq       loc  split\n",
       "0      SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...  3.823701  train\n",
       "1      SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...  3.752084  train\n",
       "2      SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...  3.540156  train\n",
       "3      SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...  3.691572  train\n",
       "4      SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...  3.688143  train\n",
       "...                                                  ...       ...    ...\n",
       "54020  SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...  1.565922   test\n",
       "54021  SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...  1.532945   test\n",
       "54022  SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...  1.529521   test\n",
       "54023  SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...  1.301030   test\n",
       "54024  SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFI...  1.302130   test\n",
       "\n",
       "[54025 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SKGEELFTGVVPILVELDGDVNGHKFSVSGEGEGDATYGKLTLKFICTTGKLPVPWPTLVTTLSYGVQCFSRYPDHMKQHDFFKSAMPEGYVQERTIFFKDDGNYKTRAEVKFEGDTLVNRIELKGIDFKEDGNILGHKLEYNYNSHNVYIMADKQKNGIKVNFKIRHKIEDGSVQLADHYQQNTPIGDGPVLLPDNHYLSTQSALSKDPNEKRDHMVLLEFVTAAGITHGMDERYK'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq['seq'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "conversion = 'ARNDCQEGHILKMFPSTWYVX'\n",
    "amino_acids = np.array([a for a in conversion])\n",
    "aa = seq['seq'].iloc[0]\n",
    "onehot_encoder = OneHotEncoder(sparse=False, categories=[amino_acids])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = seq['seq'].iloc[0]\n",
    "sequence_array = np.array(list(sequence)).reshape(-1, 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(sequence_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54025it [00:43, 1248.88it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "embed = np.zeros((len(seq), 237, 21))\n",
    "\n",
    "for i, sequence in tqdm(enumerate(seq['seq'])):\n",
    "    sequence_array = np.array(list(sequence)).reshape(-1, 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(sequence_array)\n",
    "    embed[i, :onehot_encoded.shape[0]] = onehot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed = embed.reshape(len(seq), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54025, 4977)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = (seq['split'] == 'train').values\n",
    "X_train = embed[index]\n",
    "y_train = seq[index]['loc']\n",
    "\n",
    "index = (seq['split'] == 'val').values\n",
    "X_val = embed[index]\n",
    "y_val = seq[index]['loc']\n",
    "\n",
    "index = (seq['split'] == 'test').values\n",
    "X_test = embed[index]\n",
    "y_test = seq[index]['loc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21446, 4977)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.5)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "alpha = 0.5\n",
    "clf = Ridge(alpha=alpha)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.6788691646387355, pvalue=0.0)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "spearmanr(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the learned parameters\n",
    "weights = clf.coef_\n",
    "intercept = clf.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the parameters\n",
    "np.save('weights_logf.npy', weights)\n",
    "np.save('intercept_logf.npy', intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load the parameters\n",
    "weights = np.load('weights_logf.npy')\n",
    "intercept = np.load('intercept_logf.npy')\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "weights_torch = torch.from_numpy(weights)\n",
    "intercept_torch = torch.from_numpy(np.array([intercept]))\n",
    "\n",
    "# Define a linear layer\n",
    "linear_layer = torch.nn.Linear(weights.shape[0], 1)\n",
    "\n",
    "# Set the weights and bias\n",
    "with torch.no_grad():  # We don't want these operations to be tracked by the autograd\n",
    "    linear_layer.weight.data = weights_torch\n",
    "    linear_layer.bias.data = intercept_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=4977, out_features=1, bias=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "# TEMPLATE CLASS\n",
    "class Potential:\n",
    "    \n",
    "    def get_gradients(seq):\n",
    "        '''\n",
    "            EVERY POTENTIAL CLASS MUST RETURN GRADIENTS\n",
    "        '''\n",
    "        \n",
    "        sys.exit('ERROR POTENTIAL HAS NOT BEEN IMPLEMENTED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GFP_log_flourescence(Potential):\n",
    "    \"\"\"\n",
    "    Potential for GFP log flourescence\n",
    "    \"\"\"    \n",
    "    def __init__(self, args, features, potential_scale, DEVICE):\n",
    "        weights = args['weights']\n",
    "        intercept = args['intercept']\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        weights_torch = torch.from_numpy(weights)\n",
    "        intercept_torch = torch.from_numpy(np.array([intercept]))\n",
    "\n",
    "        # Define a linear layer\n",
    "        linear_layer = torch.nn.Linear(weights.shape[0], 1)\n",
    "\n",
    "        # Set the weights and bias\n",
    "        with torch.no_grad():  # We don't want these operations to be tracked by the autograd\n",
    "            linear_layer.weight.data = weights_torch\n",
    "            linear_layer.bias.data = intercept_torch        \n",
    "        \n",
    "        self.linear_layer = linear_layer.to(DEVICE)\n",
    "        self.potential_scale = potential_scale\n",
    "        self.sequence_length = 237\n",
    "        \n",
    "    def get_gradients(self, seq):\n",
    "        \"\"\"\n",
    "        Calculate gradients with respect to log F\n",
    "\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        seq : tensor\n",
    "            L X 21 logits after saving seq_out from xt\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        gradients : list of tensors\n",
    "            gradients of seq with respect to flourescence\n",
    "        \"\"\"\n",
    "        soft_seq = torch.softmax(seq, dim=1)\n",
    "\n",
    "        if soft_seq.shape[0] > self.sequence_length:\n",
    "            soft_seq = soft_seq[:self.sequence_length]\n",
    "\n",
    "        if soft_seq.shape[0] < self.sequence_length:\n",
    "            zeros = torch.zeros(self.sequence_length - soft_seq.shape[0], soft_seq.shape[1])\n",
    "            soft_seq = torch.cat((soft_seq, zeros), 0)\n",
    "\n",
    "        score = linear_layer(soft_seq.reshape(-1))\n",
    "        score.backward()\n",
    "        gradients = soft_seq.grad\n",
    "\n",
    "        return gradients * self.potential_scale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
